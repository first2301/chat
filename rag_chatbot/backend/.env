# [필수] 벡터 저장소 경로 (컨테이너 절대경로 권장)
# 예) 컨테이너: /data/vector_db, 로컬: ./vector_db
VECTOR_STORE_PATH=

# [선택] 임베딩 설정
# 로컬 모델 디렉터리 경로 또는 허깅페이스 모델 이름
EMBEDDING_MODEL_NAME=sentence-transformers/all-MiniLM-L6-v2
# cpu | cuda (비워두면 자동 판단)
EMBEDDING_DEVICE=

# 문서 분할/검색 설정
CHUNK_SIZE=500
CHUNK_OVERLAP=50
K=20

# Ollama 설정
# 로컬 개발: http://localhost:11434
# Docker Compose 배포: http://ollama:11434
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=ko-llama-8B