services:
  # Ollama 서버
  ollama:
    build:
      context: .
      dockerfile: Dockerfile.ollama
    container_name: ollama
    ports:
      - "11435:11434"
    environment:
      - OLLAMA_HOST=0.0.0.0
    volumes:
      - ./ollama_server:/root/.ollama
      - ./ai_models:/root/.ollama/ai_models
    healthcheck:
      test: ["CMD", "ollama", "list"]
      interval: 10s
      timeout: 5s
      retries: 10

  qdrant:
    image: qdrant/qdrant:latest
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - ./vector_data/qdrant_storage:/qdrant/storage       # 네임드 볼륨 권장
      - ./vector_data/snapshot_backup:/qdrant/snapshots
    environment:
      - QDRANT__TELEMETRY_DISABLED=true
      - QDRANT__SERVICE__ENABLE_TLS=false

  backend:
    build:
      context: .
      dockerfile: Dockerfile.cpu
    container_name: rag-backend
    env_file:
      - ./backend/.env.dev
    environment:
      - QDRANT_URL=http://qdrant:6333
      - DATA_DIR=/app/data
      - EMBEDDING_MODEL_NAME=/app/embedding_models/BGE-m3-ko
    volumes:
      - ./backend:/app
      - ./embedding_models:/app/embedding_models:ro
      - ./data:/app/data:ro
    ports:
      - "8000:8000"

