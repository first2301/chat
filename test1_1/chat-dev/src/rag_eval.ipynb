{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f6ab97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rag_ollama_chroma.py\n",
    "from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.callbacks import CallbackManager, StreamingStdOutCallbackHandler\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f172b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = Path(os.getcwd()).parent.parent\n",
    "ollama_model = root_path / \"ollama-service\" / \"models\" / \"ko_llama\" / \"llama-3-Korean-Bllossom-8B.Q4_K_M.gguf\"\n",
    "embeddings_path = root_path / \"ollama-service\" / \"models\" / \"BGE-m3-ko\"\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=str(embeddings_path)\n",
    ")\n",
    "vectorstore = FAISS.load_local(\"vector_db/pcn_web2\", embedding_model, allow_dangerous_deserialization=True)\n",
    "\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 20})  # \"score_threshold\": 0.75\n",
    "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
    "\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=str(\"ko-llama-8B\"),\n",
    "    temperature=0.1,  # 약간의 다양성 부여\n",
    "    base_url=\"http://localhost:11434\",\n",
    "    callback_manager=callback_manager,\n",
    "    retriever=retriever  # retriever를 llm에 직접 설정\n",
    ")\n",
    "\n",
    "# 프롬프트를 더 명확하고 자연스럽게 개선\n",
    "system_template = (\n",
    "    '''\n",
    "    당신은 (주)피씨엔(PCN)의 친절하고 유능한 AI 어시스턴트입니다.\\n\n",
    "    사용자의 질문에 대해 신뢰할 수 있는 정보를 바탕으로 정확하고 간결하게 답변하세요.\\n\n",
    "    주어진 정보를 바탕으로 답변하세요.\\n\n",
    "    **피씨엔**, 또는 **PCN**이라는 정보를 입력받으면 피씨엔(기술), PCN 회사 소개를 답변하세요.\\n\n",
    "    피씨엔, PCN 회사 소개는 아래 내용을 기반으로 답변하세요.\\n\n",
    "    피씨엔(PCN)은 기술 회사로 Bigdata, XR, AI, SI 등 다양한 서비스를 제공합니다.\\n\n",
    "    회사개요, 프로젝트(Project), 주요 솔루션, 조직규모, 주요 고객, 연혁 등 회사 정보를 답변하세요.\\n\n",
    "    프로젝트 설명 시, 프로젝트 이름, 프로젝트 설명, 프로젝트 결과 등을 1~2문장으로 간단하게 답변하세요.\\n\n",
    "    답변에서 회사명은 PCN으로 표기하세요.\\n\n",
    "    '''\n",
    ")\n",
    "human_template = (\n",
    "    \"\"\"\n",
    "    주어진 질문은 사실에 근거하여 답변하세요.\\n\n",
    "    답변은 한글로 작성하세요.\\n\n",
    "    답변은 주어진 질문에 대해 단계별로 논리적으로 생각하여 답변해 주세요.\\n\n",
    "    질문: {question}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "chain = prompt | llm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47ba923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result1 = chain.invoke({\"question\": \"피씨엔 회사 소개\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09fa42a",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ac457b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.evaluation.qa import QAEvalChain\n",
    "\n",
    "# 평가용 질문-정답 쌍 예시\n",
    "eval_data = [\n",
    "    {\n",
    "        \"query\": \"PCN의 주요 서비스는 무엇인가요?\",\n",
    "        \"answer\": \"PCN은 빅데이터, XR, AI, SI 등 다양한 기술 서비스를 제공합니다.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"PCN의 설립 연도는 언제인가요?\",\n",
    "        \"answer\": \"PCN은 2015년에 설립되었습니다.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"PCN의 주요 고객은 어떤 산업 분야에 있나요?\",\n",
    "        \"answer\": \"PCN의 주요 고객은 금융, 제조, 유통, 교육 등 다양한 산업 분야에 있습니다.\"\n",
    "    }\n",
    "]\n",
    "predictions = []\n",
    "for item in eval_data:\n",
    "    try:\n",
    "        result = chain.invoke({\"question\": item[\"query\"]})\n",
    "        predictions.append(str(result))\n",
    "        print(f\"질문 처리 완료: {item['query'][:30]}...\")\n",
    "    except Exception as e:\n",
    "        print(f\"질문 처리 실패: {item['query']} - 에러: {e}\")\n",
    "        predictions.append(\"\")  # 빈 문자열로 채움\n",
    "print(f\"eval_data 길이: {len(eval_data)}\")\n",
    "print(f\"predictions 길이: {len(predictions)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a731364",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "# 정답과 예측이 완전히 일치하면 1, 아니면 0으로 처리\n",
    "references = []\n",
    "preds = []\n",
    "\n",
    "for item, pred in zip(eval_data, predictions):\n",
    "    if item[\"answer\"].strip() == pred.strip():\n",
    "        references.append(1)\n",
    "        preds.append(1)\n",
    "    else:\n",
    "        references.append(1)\n",
    "        preds.append(0)\n",
    "\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "precision_metric = evaluate.load(\"precision\")\n",
    "recall_metric = evaluate.load(\"recall\")\n",
    "f1_metric = evaluate.load(\"f1\")\n",
    "\n",
    "# evaluate 라이브러리는 zero_division 매개변수를 지원하지 않으므로 제거\n",
    "accuracy = accuracy_metric.compute(references=references, predictions=preds)\n",
    "precision = precision_metric.compute(references=references, predictions=preds, average=\"binary\")\n",
    "recall = recall_metric.compute(references=references, predictions=preds, average=\"binary\")\n",
    "f1 = f1_metric.compute(references=references, predictions=preds, average=\"binary\")\n",
    "\n",
    "print(\"=== 주요 성능지표 기반 RAG 평가 결과 (evaluate 사용) ===\")\n",
    "print(f\"정확도(Accuracy): {accuracy['accuracy']:.2f}\")\n",
    "print(f\"정밀도(Precision): {precision['precision']:.2f}\")\n",
    "print(f\"재현율(Recall): {recall['recall']:.2f}\")\n",
    "print(f\"F1 점수(F1 Score): {f1['f1']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efe2592",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012fa463",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd29c543",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5f710a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_chat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
