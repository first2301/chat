{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a08d079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rag_ollama_chroma.py\n",
    "from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.callbacks import CallbackManager, StreamingStdOutCallbackHandler\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "133ab72f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f:\\project_test\\solutions\\chat\\test1_1\\ollama-service\\models\\ko_llama\\llama-3-Korean-Bllossom-8B.Q4_K_M.gguf\n",
      "f:\\project_test\\solutions\\chat\\test1_1\\ollama-service\\models\\BGE-m3-ko\n"
     ]
    }
   ],
   "source": [
    "root_path = Path(os.getcwd()).parent.parent\n",
    "ollama_model = root_path / \"ollama-service\" / \"models\" / \"ko_llama\" / \"llama-3-Korean-Bllossom-8B.Q4_K_M.gguf\"\n",
    "embeddings_path = root_path / \"ollama-service\" / \"models\" / \"BGE-m3-ko\"\n",
    "print(ollama_model)\n",
    "print(embeddings_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13eb094f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\project_test\\solutions\\chat\\.venv_chat\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# HuggingFace 임베딩 모델 로드 (경로를 문자열로 변환하여 오류 방지)\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=str(embeddings_path)\n",
    ")\n",
    "# llm = Ollama(model=str(ollama_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af535fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS.load_local(\"vector_db/pcn_web\", embedding_model, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce4e2ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\project_test\\solutions\\chat\\.venv_chat\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "query_embedding = embedding_model.embed_query(\"피씨엔 소개\")\n",
    "\n",
    "# 벡터 유사도 검색 (상위 3개 결과 반환)\n",
    "results = vectorstore.similarity_search_by_vector(query_embedding, k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56b45131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색기(Retriever) 설정 (개선)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 20})  \n",
    "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=str(\"ko-llama-8B\"),\n",
    "    temperature=0.1,  # 약간의 다양성 부여\n",
    "    base_url=\"http://localhost:11434\",\n",
    "    callback_manager=callback_manager,\n",
    "    retriever=retriever  # retriever를 llm에 직접 설정\n",
    ")\n",
    "\n",
    "# 프롬프트를 더 명확하고 자연스럽게 개선\n",
    "system_template = (\n",
    "    '''\n",
    "    당신은 친절하고 유능한 AI 어시스턴트입니다.\n",
    "    사용자의 질문에 대해 신뢰할 수 있는 정보를 바탕으로 정확하고 간결하게 답변하세요.\n",
    "    주어진 정보를 바탕으로 답변하세요.\n",
    "    **피씨엔**, 또는 **PCN**이라는 정보를 입력받으면 피씨엔(기술), PCN 회사 소개를 답변하세요.\n",
    "    피씨엔, PCN 회사 소개는 다음과 같습니다.\n",
    "    피씨엔(PCN)은 기술 회사로 빅데이터, XR, AI, SI 등 다양한 서비스를 제공합니다.\n",
    "    회사개요, 프로젝트(Project), 핵심 역량 및 사업 분야, 미션, 비전, 가치, 주요실적 및 프로젝트, 조직 규모 및 연혁 등 회사 정보를 답변하세요.\n",
    "    답변에서 회사명은 PCN으로 표기하세요.\n",
    "    '''\n",
    ")\n",
    "human_template = (\n",
    "    \"아래의 질문에 대해 단계별로 논리적으로 생각하여 답변해 주세요.\\n\"\n",
    "    \"질문: {question}\"\n",
    ")\n",
    "\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22240a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke({\"question\": \"피씨엔 회사 소개\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b5e3bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb47bc87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_chat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
